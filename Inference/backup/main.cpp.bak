//
// Program Entrance of NeurIoT
// Here Define the overall flow
//
#include "opWrapper.h"
#include "dataLoader.h"
#include "shuffleUnit.h"
#include <arm_compute/runtime/Scheduler.h>

#include "unistd.h"

#include "mpi.h"
#include <iostream>

void partlyGather(void *sendbuf, void *recvbuf, MPI_Comm comm, int rank, int size, int count, MPI_Request array_of_requests[])
{
	MPI_Request request_tmp;
	for(int i = 0; i<size; i++)
	{
		if(i != rank)
		{
			MPI_Irecv((uint8_t*)recvbuf+count*i*4, count, MPI_FLOAT, i, 100, comm, array_of_requests);//+count*i*16
			array_of_requests++;
		}
		
	}
	
	for(int j = 0; j<size; j++)
	{
		if(j != rank)
		{
			MPI_Isend((uint8_t*)sendbuf+count*j*4, count, MPI_FLOAT, j, 100, comm, &request_tmp);//+count*j*16
		}
	}
}

void pointExchange(void * tmp0, void * tmp1){
	void *tmp2 = tmp0;
	tmp0 = tmp1;
	tmp1 = tmp2;
}


int main(int argc, char **argv)
{
	if(argc != 3)
	{
		std::cout<<"Usage: mpiexec -hostfile [hosts] -np [4] -host [raspberrypi0,raspberrypi1] ./main [numberThread(1)] [numberIteration(100)]"<<std::endl;
		MPI_Finalize ();
		return 0;
	}	
	
	arm_compute::Scheduler::get().set_num_threads(atoi(argv[1]));
	//通过控制
	
	
    int rank, size;
    //char version[MPI_MAX_LIBRARY_VERSION_STRING];
	//Init MPI Env
    MPI_Init (&argc, &argv);
	MPI_Comm_rank(MPI_COMM_WORLD, &rank);
	MPI_Comm_size(MPI_COMM_WORLD, &size);
	double start , finish;
   
	/******************************
		Init Tensor and Layer
	******************************/
	
	//Output Tensor
	Tensor * conv1_out = new Tensor();
	Tensor * maxpool_out = opWrapper::configure3DTensor(56,56,6);
	Tensor * conv1_bn_out = new Tensor();	
	Tensor * unit1_out = new Tensor();
 	Tensor * unit2_out = new Tensor();
	Tensor * unit3_out = new Tensor();
	Tensor * unit4_out = new Tensor();
	//Tensor * cs4_out_1 = new Tensor();
	Tensor * unit5_out = new Tensor();
	Tensor * unit6_out = new Tensor();
	Tensor * unit7_out = new Tensor();
	Tensor * unit8_out = new Tensor();
	Tensor * unit9_out = new Tensor();
	Tensor * unit10_out = new Tensor();
	Tensor * unit11_out = new Tensor();
	Tensor * unit12_out = new Tensor();
	// Tensor * cs12_out = new Tensor();
	Tensor * unit13_out = new Tensor();
	Tensor * unit14_out = new Tensor();
	Tensor * unit15_out = new Tensor();
	Tensor * unit16_out = new Tensor();
	// Tensor * cs16_out_1 = new Tensor(); 
	Tensor * conv5_out = new Tensor();
	Tensor * conv5_bn_out = new Tensor();
	
	//Input Tensor
	pmLoader ppm;
	ppm.open("/home/pi/NeurIoT_mpi/go_kart.ppm");	
	Tensor * input = new Tensor();
	ppm.init_image(*input, Format::F32);	
	
	//Layer
	
	NEConvolutionLayer * conv1 = opWrapper::ConvolutionLayer(input, conv1_out, 2, 1, 3, 3, 3, 6);
	NEBatchNormalizationLayer * conv1_bn = opWrapper::BNLayer(conv1_out,conv1_bn_out, 6);
	NEPoolingLayer * maxpool = opWrapper::MaxPoolLayer(conv1_bn_out, maxpool_out, 3, 2);
	opWrapper::shuffleUnit * Unit1 = new opWrapper::shuffleUnit(maxpool_out, unit1_out, 2, 6, 68);
	opWrapper::shuffleUnit * Unit2 = new opWrapper::shuffleUnit(unit1_out, unit2_out, 1, 68,68);
	opWrapper::shuffleUnit * Unit3 = new opWrapper::shuffleUnit(unit2_out, unit3_out, 1, 68,68);
	opWrapper::shuffleUnit * Unit4 = new opWrapper::shuffleUnit(unit3_out, unit4_out, 1, 68,68);
	opWrapper::shuffleUnit * Unit5 = new opWrapper::shuffleUnit(unit4_out, unit5_out, 2, 68,136);
	opWrapper::shuffleUnit * Unit6 = new opWrapper::shuffleUnit(unit5_out, unit6_out, 1, 136,136);
	opWrapper::shuffleUnit * Unit7 = new opWrapper::shuffleUnit(unit6_out, unit7_out, 1, 136,136);
	opWrapper::shuffleUnit * Unit8 = new opWrapper::shuffleUnit(unit7_out, unit8_out, 1, 136,136);
	opWrapper::shuffleUnit * Unit9 = new opWrapper::shuffleUnit(unit8_out, unit9_out, 1, 136,136);
	opWrapper::shuffleUnit * Unit10 = new opWrapper::shuffleUnit(unit9_out, unit10_out, 1, 136,136);
	opWrapper::shuffleUnit * Unit11 = new opWrapper::shuffleUnit(unit10_out, unit11_out, 1, 136,136);
	opWrapper::shuffleUnit * Unit12 = new opWrapper::shuffleUnit(unit11_out, unit12_out, 1, 136,136);
	opWrapper::shuffleUnit * Unit13 = new opWrapper::shuffleUnit(unit12_out, unit13_out, 2, 136, 272);
	opWrapper::shuffleUnit * Unit14 = new opWrapper::shuffleUnit(unit13_out, unit14_out, 1, 272, 272);
	opWrapper::shuffleUnit * Unit15 = new opWrapper::shuffleUnit(unit14_out, unit15_out, 1, 272, 272);
	opWrapper::shuffleUnit * Unit16 = new opWrapper::shuffleUnit(unit15_out, unit16_out, 1, 272, 272);
	NEConvolutionLayer * conv5 = opWrapper::ConvolutionLayer(unit16_out, conv5_out,1, 0, 1, 1, 272, 256);
	NEBatchNormalizationLayer * conv5_bn = opWrapper::BNLayer(conv5_out,conv5_bn_out, 256);
	std::cout<<rank<<", Initialization Finished!"<<std::endl;
	/******************************
		Init Run Function
	******************************/
	//Fill Input
	input->allocator()->allocate();
	if(ppm.is_open())
	{
		ppm.fill_image(*input);
	}	
	ppm.close(); 
	
	MPI_Barrier(MPI_COMM_WORLD);
	start = MPI_Wtime();
	
	MPI_Request array_of_requests[size-1];
	MPI_Status array_of_statuses[size-1];
	int flag = 0;
	
	void *pTmp0 = (void*)(new float[53312]);
	void *pTmp1 = (void*)(new float[26656]);
	void *pTmp2 = (void*)(new float[13328]);
	
	
	for(int i = 0; i<atoi(argv[2]); i++){
	//Run Per Layer
		conv1->run();	
		conv1_bn->run();
		maxpool->run();
		Unit1->run();
		Unit2->run();
		Unit3->run();
		Unit4->run();
		//comm 28*28*272
		//unit4_out
		
		partlyGather(unit4_out->buffer(), pTmp0, MPI_COMM_WORLD, rank, size, 13328, array_of_requests);		
		
		while(!flag)
		{
			usleep(100);
			MPI_Testall(size-1, array_of_requests,&flag, array_of_statuses);			
		}
		flag = 0;
		pointExchange(pTmp0, unit4_out->buffer());
		
		Unit5->run();
		Unit6->run();
		Unit7->run();
		Unit8->run();
		Unit9->run();
		Unit10->run();
		Unit11->run();
		Unit12->run();
		//comm 14*14*544
		//unit12_out
		partlyGather(unit12_out->buffer(), pTmp1, MPI_COMM_WORLD, rank, size, 6664, array_of_requests);			
		while(!flag)
		{
			usleep(100);
			MPI_Testall(size-1, array_of_requests,&flag, array_of_statuses);			
		}
		flag = 0;
		pointExchange(pTmp1, unit12_out->buffer());
		
		Unit13->run();
		Unit14->run();
		Unit15->run();
		Unit16->run();
		//comm 7*7*1088
		//unit16_out
		partlyGather(unit16_out->buffer(), pTmp2, MPI_COMM_WORLD, rank, size, 3332, array_of_requests);
		while(!flag)
		{
			usleep(100);
			MPI_Testall(size-1, array_of_requests,&flag, array_of_statuses);			
		}
		flag = 0;
		pointExchange(pTmp2, unit16_out->buffer());
		
		
		conv5->run();
		conv5_bn->run();
	}
	
	finish = MPI_Wtime();
	
	std::cout<<rank<<", Running Finished!"<<std::endl;
	
	if(rank==0){
		std::cout<<"Elapsed time is "<< finish-start <<" seconds"<<std::endl;
		std::cout<<"时间精度是 "<<MPI_Wtick()<<" 秒钟"<<std::endl;
	}
	
	/******************************
		run and comm
	******************************/

	
	
	
   
   
   
	//MPI Finalize
	MPI_Finalize ();

    return 0;
}
